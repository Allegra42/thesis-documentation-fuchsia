% !TEX root = MasterThesis.tex

\chapter{Modern Operating System Concepts}\label{ch:modern-os-concepts}
%
%https://groups.google.com/forum/#!topic/comp.os.minix/wlhw16QWltI%5B1-25%5D
 % 2: your job is being a professor and researcher: That's one hell of a
% good excuse for some of the brain-damages of minix. I can only hope (and
% assume) that Amoeba doesn't suck like minix does.
% >1. MICROKERNEL VS MONOLITHIC SYSTEM
% True, linux is monolithic, and I agree that microkernels are nicer. With
% a less argumentative subject, I'd probably have agreed with most of what
% you said. From a theoretical (and aesthetical) standpoint linux looses.
% If the GNU kernel had been ready last spring, I'd not have bothered to
% even start my project: the fact is that it wasn't and still isn't. Linux
% wins heavily on points of being available now.
%
This thesis' introduction already picked up the discussion about which operating system architecture is the superior one by refering to the \textit{Tanenbaum-Torvalds debate}\cite{linux-is-obsolete} in 1992.
Besides the discussion is quite interessting from todays view on different operating systems, the forecasts on their future and the actual development, are both, \textsc{Tanenbaum} and \textsc{Torvalds} underpinning their arguments with the origins of their implementations \textit{MINIX} and \textit{Linux} in different problems. 
And roughly spoken are exactly such different problems which needs to be solved with an operating system one reason for their diversity. 
Over the years, they had to fit in solving very different kinds of problems on very different kinds of hardware, which resulted in many different ways of working and architectures. 
As with the debate, it is rather difficult to impossible to find one architectural concept or implementation which is clearly superior to the other ones in every use-case. 
Nevertheless, it is a reasonable question why a majority of the operating system kernels which were developed from scratch in the last few years are based on a microkernel concept.
In 2009, the official statement of the Linux kernel developer \textsc{Richard Gooch} was still that monolithic kernels are superior for performance reasons\cite{why-linux-monolith}.
So the question remains what changed during the last ten years to promote this change, and especially for this work, how this affects on device driver development.
For this reason, this chapter is dedicted to the basic components and functionallities of operating system kernels and how they are implemented in the real world examples \textit{Linux} and \textit{Zircon}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Links
%
% Some notes to Linux design decisions: \url{http://vger.kernel.org/lkml/#s15-3}
% Memory management in Linux -> Files from LFD 430
% 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Operating System Architectures}\label{sec:kernel-arch-concepts}

% TODO OS design goals see Betriebssysteme Glatz 
As already pointed out are architectural decisions for operating systems commonly influenced by the issues they are intended to solve.
By giving priority to some design objectives that are pertinent to the underlying issue, different concepts and architectures are the outcome.
According to \textsc{Glatz}\cite{glatz2015betriebssysteme} are some of them:
\begin{itemize}
    \item Providing a reliable, crash-proof environment.
    \item Providing a portable operating system.
    \item Providing a scalable operating system, e.g.\ in terms of processing cores.
    \item Providing an extensibile operating system, e.g.\ in terms of adding additional functionality to the kernel.
    \item Providing real-time capabilities.
    \item Providing an efficient design in terms of ressources and performance.
    \item Providing a secure environment for user applications.
    \item Providing a maintainable operating system, e.g.\ by the division of policy and mechanism. 
\end{itemize}\ \\
%
In addition, operating systems should also pay attention to the common software design issue \textit{mechanism vs.\ policy}.
That means an operating system design should provide a clear distinction between the \textit{mechanism}, that means the capable abilities that can be performed (how is something done) and the \textit{policy}, which controlls how the available capabilities are used (what is done)\cite{lfd430},~\cite{silberschatz2009operating}.
An example for driver development could be controlling the number of processes that can use a device at once.
In this case, the driver should provide the mechansim, the \textit{how} such a limitation could be done, but not \textit{what}, the actual number of allowed processes. 
The idea behind is that requirements may change over some time and such a distinction makes it easy to adjust the \textit{policy} via some parameters without touching the underlying \textit{mechanism}\cite{silberschatz2009operating}.

How these design principles fit into the known operating system architectures will be considered in the following sections.
But before, the terms \textit{kernel mode} and \textit{user mode} will be explained as they are fundamental for this work.

\subsubsection*{Dual-Mode Execution}
Modern general purpose \acp{cpu} provide a ring based, hardware enabled security model which had it's origin in the Intel x86 processor architecture\cite{tanenbaum-modern-operating-systems}.
It is usually made of four different security levels, the rings 0 to 3 which are illustrated in Figure~\ref{pic:x86rings}.
In this model, ring 3 is the least secure level, used for common user applications (even if started with extended privileges (\textit{root} for the UNIX-like world)), while ring 2 is used for libraries shared between user applications and ring 1 is for system calls\cite{glatz2015betriebssysteme}.
System calls provide the transition to ring 0, the one with the topmost security level, which is used for the operating system kernel.
As a crucial part of an operating system, they will be discussed in more detail later in this work.

Directly related to this model is the \textit{dual-mode} execution mode of modern \acp{cpu}.
It is a hardware enabled security concept to provide a distinction between the user applications in ring 3 and the actual operating system kernel in ring 0.
Just the kernel in ring 0, running in the \textit{kernel mode} (or \textit{privileged mode, supervisor mode or system mode}), has direct and privileged access to memory, hardware, timers or interrupts, e.g.\ for performing \ac{io} operatings or memory mappings\cite{lfd430}.
User applications in ring 3, running in the \textit{user mode}, are not allowed to them so directly, they have limited privileges and a limited instruction set.
As named above, they need to use a mechanism called \textit{system calls} to transfer the execution to the \textit{kernel mode} where the priviledged actions are performed.
Lastly, the execution is transfered back to the calling user process and with this, the mode changes back to \textit{user mode}.
Figure~\ref{pic:mode-switches} pictures the operating flow of a system call including the mode switches between \textit{user} and \textit{kernel mode}.

%
%
\begin{figure} [ht]
	\centering
	\includegraphics[scale=0.6]{x86Rings}
	\caption{The Rings of the x86's security concept\cite{glatz2015betriebssysteme}}\label{pic:x86rings}
    %TODO own picture!
\end{figure}
%
\begin{figure} [ht]
	\centering
	\includegraphics[scale=0.6]{mode-switch}
    \caption{A system calls sequence including the mode switches\cite{glatz2015betriebssysteme}}\label{pic:mode-switches}
    %TODO own picture!
\end{figure}

The \ac{cpu}'s operating mode is usually controlled by a specific bit in the \ac{psw}\cite{tanenbaum-modern-operating-systems}.
It influences the state of each \ac{cpu} core itself in a multi-processor system, but not the operating system kernel.
As a result, different \ac{cpu} cores may be in a different execution mode\cite{lfd430}.
With this seperation, any priviledged instruction is forbidden in \textit{user mode} and will not be executed.

Based on the dual mode execution on the \ac{cpu}, different architectural concepts for operating systems evolved.
They differ e.g.\ in the share of the operating system respectively the operating system's kernel actually running within the \ac{cpu}'s \textit{kernel mode}. 
Thus, they have an influence on the whole system, including device driver development but also on performance and security issues.

With this basic knowledge about the \ac{cpu}'s operating modes, the next section researches a selection of different operating system architectures.
Special attention should be paid to the most common ones, the \textit{monolithic} and the \textit{microkernel} architectures and their implementation in Linux and Zircon.
On the contrary, this work will not take a particular look on special purpose operating system architectures such as ones for loosely coupled multi-processor systems known from processing clusters.
Today, even the majority of general purpose computing systems are driven by more than one \ac{cpu} and most of common modern operating systems are designed to provide support for the defacto standard for tightly coupled systems, \ac{smp}.


\subsection{Monolithic Architectures}\label{sec:monolithic-archs}
Some sources, such as \textsc{Glatz}\cite{glatz2015betriebssysteme} or \textsc{Silberschatz}\cite{silberschatz2009operating}, suggest monolithic operating systems do not have a well-defined structure at all. 
As they are indeed most commonly grown structures, started in a completely different scope (MS-DOS, the original UNIX), it is not an incorrect claim.
But it does not neccessarily have to be the case.
Above all, monolithic operating system (kernel) architectures have in common that they form one single binary program which is running entirely in kernel mode.
User programms, running in user mode, interact with the kernel only through a well defined set of \textit{system calls}\cite{lfd430}. 
Within the kernel itself, all parts are free to use and access each other but also the hardware, without any limitation, e.g.\ regarging the access of kernel functionalities of another component or hardware acces. 
That means a function or procedure initial developed for scheduling processes could be used in a completely different context if its functionality is useful to solve another issue.
In fact, there is no information hiding between kernel functions or procedures.
Any function in this kernel context has full access to the hardware, such as \ac{io} devices, timers, interrupts and even to the memory. 
There is no memory protection or validation between different components of a monolithic kernel. 
Of course, this leads to some serious disadvantages in this architecture, for example could a crash in one single function or procedure crash the entire kernel or the resulting system may become difficult to understand and maintain\cite{tanenbaum-modern-operating-systems},~\cite{silberschatz2009operating}.
The missing memory protecting within the kernel could also be a source for crashes or attacks.
But in contrast, this design also enables a very efficient kernel design without any unneeded communication overhead or hardware inefficiencies\cite{lfd430}.

An extension of the monolithic architecture are the so-called \textbf{modular operating systems}.
They provide additional, defined interfaces for (in common) dynamically loadable and unloadable extentions, e.g.\ for device drivers or filesystems. 
Sometimes, such extensions or modules are just allowed to use a limited function set of the operating system, but they are still running as a part of the kernel in kernel mode\cite{lfd430},~\cite{tanenbaum-modern-operating-systems}. 
Just like ordinary kernel functions or procedures, (malicious) programming errors in extentions may lead to a kernel crash or manipulate or damage other components.
Contrary, the modular concept provides some advantages over regular monolitic kernels.
It allows to slim down the actual kernel by providing the chance to reload only the actually needed functionality dynamically and e.g.\ security patches within such an extension is possible without restarting the entire system\cite{brause2017betriebssysteme}.
As the extensions become an part of the operating system running in kernel mode, no additional communication effort between the actual kernel and the modules is required.
Thus, concept of modules is quite popular for basically monolithic operating systems like \textit{Linux} or \textit{Solaris}\cite{brause2017betriebssysteme},~\cite{silberschatz2009operating}.


\subsection{Microkernel Architectures}\label{sec:microkernel-archs}
The microkernel architecture focuses on very opposite design goals compared to the monolithic one. 
Some of them are to cope the complexity, rather poor maintainablity and susceptibility to errors by a massively modular approach. 
To archive this, the core idea behind microkernels is to provide only a very small kernel running in kernel mode which only provides the core functionalities while all the other important functions of an operating system are running in user mode.
Thereby, the microkernel architecture is excellently suited to implement a proper division of mechanism and policy.
The kernel provides just the most basic mechanisms needed for an operating system, while the userspace modules implement the policy.
This decoupling makes it easier to change the policy in userspace for altering requirements without touching the actual kernel\cite{tanenbaum-modern-operating-systems}.

What is part of this core functionality differs between miscellaneous sources, but all considered ones are in agreement that a simple mechanism for process scheduling is as well a core functionality as providing an \ac{ipc} mechanism\cite{lfd430},~\cite{silberschatz2009operating},~\cite{glatz2015betriebssysteme}.  
In contrast, the sources disagree as to whether memory management and virtualisation, device drivers or synchronization facilities are a part of the actual kernel.
The \textit{Mach} microkernel, which formed the first generation of microkernels in 1985, named process and thread administration, an extensible and secure \ac{ipc} mechanism, virtual memory management and scheduling as its core tasks, while everything else needed has to run in usermode\cite{rashidMach}.
Functional enhancements of the system do not require changes to the kernel itself, too.
This concerns, depending on the exact relization, device drivers, memory management, system call handlers and even more system components\cite{lfd430},~\cite{silberschatz2009operating}.
In academic microkernel approaches, all components in user mode run within an own userspace process as small, well-defined modules, while the communication is done through copious message passing via the actual kernel\cite{tanenbaum-modern-operating-systems},~\cite{lfd430}.
Since the restrictions by the \ac{cpu}'s dual mode still apply for microkernel based operating systems is it not allowed to device drivers running in user mode to have direct physical access to \ac{io} ports as a consequence.
A device driver has to invoke the actual kernel to perform the needed action substitional.
But thus, the kernel is able to check the action and whether the driver is authorized to executed them.
Resulting, the microkernel design is more reliable and secure as such a division enables the kernel to intercept erroneous actions such as accidental memory writes to important regions\cite{tanenbaum-modern-operating-systems}.
Equally a crash in a userspace system component like a driver is not able to crash the entire kernel in such an approach. 
And as an additional advantage facilitate the microkernel architecture porting the operating system kernel to another target architecture as the most hardware dependencies are part of the small kernel\cite{silberschatz2009operating},~\cite{lfd430}.

With all the named advantages microkernels offer, the question remains why microkernels are only spread in real-time, avionics or military but not for desktop operating systems.
One reason is that all these advantages are bought at the high price of microkernel message costs.
For the named application areas, especially the reliability that comes with the microkernel architecture is more desirable than the performance costs of the lot more context switches in comparison to monolithic architectures\cite{tanenbaum-modern-operating-systems}.
Since a lot of the operating system's functionality has been moved to the userspace, microkernel architectures need to perform noticable more context switches to invoke the actual kernel for privileged actions. 
The performance losses are not only caused by the large amount of context switches themselves, but also by the fact that modern \acp{cpu}, particularly the caches are not designed for them. 
Every context switch causes cache misses which trigger that the required data has to be loaded from the slower main memory and cached. 
The data of the previous context (e.g.\ the user mode context) will be displaced from the cache and the \ac{cpu} is largely blocked in the meantime.
By rapidly switching back to the previous context, as is usual for e.g.\ a short kernel invokation to perform an \ac{io} operation on microkernel architectures, the cache is no longer suitable for the new context and has to be replaced\cite{lfd430}.

First of all, the \textit{L4} kernel, a second generation microkernel was able to get close to the performance of a monolithic kernel as \textit{Linux} it is\cite{Hrtig1997}.   
Nevertheless are pure microkernels mainly used for systems with high reliability requirements but unusual for desktop application. 
Some industry examples are \textit{Integrity}, \textit{QNX} and \textit{seL4}, a mathematically verified version of the \textit{L4} kernel\cite{tanenbaum-modern-operating-systems}. 

%TODO ? reincarnation server : check if all modules are up running and work correctly -> if not it replaces them without user interaction \cite{tanenbaum}
%TODO picture \cite{microkernels}


\subsection{Layered Architectures}
Layered operating system architectures are usually organized in hierachical layers, but sometimes the choosen model is described as a series of concentric rings.
Each layer or ring provides a group of functionality while a it is only allowed to use the functions of the one directly below. 
The cooperating between the layers or rings is regulated by clearly defined interfaces\cite{brause2017betriebssysteme}.
This is usually accompanied by the fact that the lower layers or inner rings are more privileged as the outer ones.
However, there is no uniform and univerally accepted approach for division in layers and their count accoring to this pattern\cite{glatz2015betriebssysteme},~\cite{tanenbaum-modern-operating-systems}.
In fact, a meaningful division is not that easy.
Functionalities may have to be divided artifically and the harmonious arrangement can have its pitfalls caused by the access requirements this architecture is based on.
Is the layered access model considered properly to get a clean architecture, it that can unfold its advantages.
These are for example the interchangeability of the layers if they and their interfaces were properly designed or the resulting concept for debugging.
As the layers are constructed on top of each other, it is possible to debug  and verify each one for its own, starting at the lowest layer up to the top most one\cite{silberschatz2009operating}.
But also the costs for system calls are comparatively high, because they have to be passed though all layers while each one adds overhead to such a call\cite{silberschatz2009operating}.  

In general, layered operating system architectures are related to monolitic ones, but it is conceivable to adopt the idea for microkernel approaches, e.g.\ is the MINIX userspace divided into layers. 
Examples for this architecture are \textit{OS/2} or newer \textit{Unix} variants, while \textit{Multics} is one for a concentric rings based model\cite{glatz2015betriebssysteme},~\cite{tanenbaum-modern-operating-systems}.


% \subsection{Distributed Architectures}


\subsection{Hybrid Architectures}
Hybrid operating system architectures based on monolithic, microkernels and may be the layered ones are common approach to combine the advantages of these concepts.
They try to pair the performance of the monolithic design with the modularity and reliability of microkernels\cite{microkernels},~\cite{silberschatz2009operating}.
How both worlds interact is very different depending on the exact implementation.
\textsc{Silberschatz} explains one of them in his book \textit{Operating System Concepts}\cite{silberschatz2009operating} using Apple's \textit{OS X} (today named \textit{macOS}) as an example.
Depending on the exact implementation and the share of the architectures, most disadvantages of monolithic architectures still apply for the hybrid systems.
Further examples for hybrid architectures are \textit{Windows NT} and \textit{BeOS}\cite{microkernels}.  


\subsection{The Linux Kernel's Monolithic Architecture}

Linux is the perfect example for an extremly grown operating system.
Starting as a pure hobby project to learn about a specific \ac{cpu} and connect to the Unix computers at \textsc{Linus Torvalds}, its initial author's, university, it becomes strongly related to its archetype, \textit{Unix}\cite{DiamondTorvalds2002}. 
They share fundamental design goals, just like beeing capable of multiple processors and user at the same time, but Linux is not based on the origin Unix source code\cite{tanenbaum-modern-operating-systems}.
The overall architecture of the Linux kernel is, as already named, monolithic and also inspired by Unix\cite{lfd430},~\cite{DiamondTorvalds2002}.
It is entirely running in kernel mode and all built-in layers have full access to the internal kernel \ac{api} using common function calls like in C.
A sophisticated concept of kernel modules which can be dynamically loaded to a running kernel makes a limited number of microkernel advantages available for Linux.
Modules in Linux are only allowed to use a restricted (exported) set of functions to use, but once loaded to the running kernel, they become a part of the monolith running in kernel mode\cite{lfd430}.
Linux is largely compatible to the \ac{posix} standard which was initially created for Unix.
Initally, it was because \textsc{Torvalds} could not get a version of the standard, while today it is rather a conscious decision\cite{DiamondTorvalds2002},~\cite{tanenbaum-modern-operating-systems}. 
Also the decision for the monolithic architecture is today consciously supported by the kernel community and justified with its performance and efficiency over microkernels due to the \textit{priviledge barrier} between user and kernel mode which has to be passed quite often in microkernel architecture\cite{why-linux-monolith},~\cite{lfd430}.
The Linux kernel itself is divided in five essential tasks which are also reflected in its source code.
They are: 
\begin{itemize}
    \item Process Management,
    \item Memory Management,
    \item Filesystems,
    \item Device Management and
    \item Networking\cite{lfd430}.
\end{itemize}
By structuring this tasks and further components into \textit{subsystems} like \textit{drivers/}, \textit{fs/} (filesystems), \textit{net/} or \textit{kernel/}, the linux kernel remains comprehensible and in some ways modular. 
A closer look to the most of them in general but also their implementation in Linux is done in the following sections.

The Linux kernel is mainly written in C but some very hardware dependent part are in Assembly. 
Additionally, especially the Assembly parts were strongly dependent on the \ac{gcc}.
Today, there are some efforts to reduce the share of Assembly for maintenance and readability since modern compilers do not generate less efficient code as hand-written Assembly is\cite{programming-religion}.
This also reduces the dependency to \ac{gcc} and enables the use of alternative compilers, especially Clang\cite{linux-clang},~\cite{fosdem-linux-llvm}.
Nevertheless, the Linux kernel's principal lanugage is C and it only provides support for C drivers. 


\subsection{The Zircon Kernel's Microkernel Architecture}
% design goals, architecture, interface posix, parts, language/compiler
In contrast to the Linux kernel, Zircon is not a grown structure.
Started in 2015, it was largely developed from scratch by Google for a so far undisclosed field of application\cite{chat-zircon-arch}.
Nevertheless, Zircon emerged from a branch of \textit{Little Kernel} (LK) by \textsc{Travis Geiselbrecht} which is also a part of the Zircon Team at Google\cite{zircon-vs-lk}. 
Despite its origin, Zircon is very differnt to Little Kernel.
It targets powerful devices such as modern computers and phones and provides for this reason only 64-bit support, first class user-mode support and a capability-based security model. 
In contrast, Little Kernel is designed for embedded applications and amongst others used as bootloader for \textit{Android} and as \textit{Android Trusted Execution Environment (Trusty TEE)}\cite{lk-intro}.
It has 32-bit support, but none of the more sophisticated features Zircon has\cite{zircon-vs-lk}.

The mirokernel architecture is justified by having security, safety, reliability and modularity as major design goals for Zircon.
According to \textsc{Travis Geiselbrecht} was the architecture a conscious tradeoff between the named goals and performance\cite{chat-zircon-arch}.
They try avoid costly context switches as much as possible, speed up the remaining ones and take advantage from \ac{smp}, but it is not the focus of Zircon.
Alike, Zircon does not focus on performing \ac{io} operatings or process management which are the key tasks \ac{posix} was designed for\cite{chat-zircon-arch}.
As a result, Zircon does not claim to be or to become \ac{posix} compatible, they just support a very basic subset of the standard\cite{zircon-libc-posix}.
% For \ac{ipc} Zircon provides a mechansim based on an \ac{idl} which is widly used within the Zircon kernel but also in Fuchsia as the whole operating system.
The Zircon kernel itself is splitted up into the actual microkernel running in kernel mode (\textit{kernel/}) and services, drivers and core libraries running in user mode (\textit{system/})\cite{zircon-intro}.
The kernel part provides the basic operating system mechanisms: 
\begin{itemize}
    \item Process Management,
    \item (virtual) Memory Management,
    \item \acl{ipc} and
    \item Synchronization Mechanisms\cite{zircon-intro}.
\end{itemize}
The part running in user mode contains core services for, amongst others, booting, device management and networking, device drivers respectively hardware related code and user libraries.

Zircon is for the most parts written in C++ and less in C.
It provides native support for device drivers in both languages but due to the fact Zircon provides an \ac{idl} which defines a contract for in-process drivers, other languages are conceivable as well.
In fact, support for Rust drivers is currently beeing worked on\cite{chat-zircon-arch}.
Unlike Linux, Zircon provided support for both, the \ac{gcc} and the Clang compiler, from the beginning caused by the sophisticated tools aroung Clang and LLVM\@.


\section{System Calls}\label{sec:system-calls}
System calls were already marginally mentioned in this work as the mechanism to switch the program execution between user and kernel mode, because  applications running in user mode have only restricted rights.
Thus, this special calls are needed for the interaction with basic hardware devices like the \ac{cpu}, the memory, peripherals or filesystems and for invoke the actual operating system's kernel for management operations like process management\cite{lfd430}. 
System calls are to a high degree hardware dependent and differ between various operating system implementations.
% Even operating systems which comply the \acf{posix} standard may differ in the typ and number of available system calls.
% The wide-spread \ac{posix} standard is only an \ac{api} definition but not one for system calls.
% An operating system may implement the \ac{posix} standard functions within a library which often involve system calls, but it has not to do so\cite{lfd430},~\cite{glatz2015betriebssysteme}.
% Equally, a system is not constrained to a single \ac{api} and may implement different ones using its existing set of system calls\cite{glatz2015betriebssysteme}.
% \ac{posix} is implemented is a very common standard which is for example implemented in UNIX, macOS, MACH and partly in Linux\cite{tanenbaum-modern-operating-systems},~\cite{glatz2015betriebssysteme}.
% Another example for an \ac{api} is Win32 used by Windows to abstract their system calls.
% As a result system calls are rarely used directly by user applications without an abstraction layer such as libraries. An example is the \textit{libc}\cite{lfd430},~\cite{tanenbaum-modern-operating-systems}.
%

A system call has its origin in an application running in user mode.
If the application has to invoke the operating system kernel, e.g.\ to perform an action on memory in substition, it has to use one for switching the operating mode\cite{glatz2015betriebssysteme},~\cite{tanenbaum-modern-operating-systems}.
As switching the \ac{cpu}'s execution mode also means a new context, a system call to the kernel differs from a common procedure call.
In user mode, the so-called entry code stores the system call's parameters in a defined way.
One is to store the parameters and the call's number in defined registers (see~\ref{pic:syscalls}), another one is to store them on stack, according the C/C++ calling in reverse order\cite{silberschatz2009operating},~\cite{glatz2015betriebssysteme}.
The exact one depends on the actual \ac{cpu} architecture.
The following instruction triggers a specical software interrupt containing the order to switch the context.
It is also named \textit{trap instruction}\cite{glatz2015betriebssysteme},~\cite{tanenbaum-modern-operating-systems}.
To be exact, it is the interrupt vector number of the trap instruction which is responsible for the switch.
They are \texttt{0\x80} on Linux as pictured in~\ref{pic:syscalls} and \texttt{0\x2e} on Windows systems\cite{glatz2015betriebssysteme}.
But right before switching it is needed to save the \acf{psw}, which contains the actual processors state includes the mode bit, to the stack.
The same number is used in kernel mode as an index within the interrupt vector table (or interrupt discriptor table, IDT) which contains the start address of the system service dispatcher routine (compare to~\ref{pic:syscalls}).
This tables content, the system serice dispatcher routine, is loaded as next instruction to the new \ac{psw}\cite{brause2017betriebssysteme}.
Jumping to this routine, the system call's parameters and its number are restored to examine the actual call and invoke the matching service routine from the system service dispatching table which finally fulfils the requested action as simplified pictured in~\ref{pic:syscalls}\cite{glatz2015betriebssysteme}.
Conclusively, the control flow jumped back to the system service dispatcher which hands the controll back to user space inclunding switching back to user mode in the common way to return\cite{glatz2015betriebssysteme}.
The previous \ac{psw} is restored from stack containing the bit for \ac{cpu}'s user mode execution.
The user application has to clean up the stack like for each procedure call at the very end\cite{tanenbaum-modern-operating-systems}.

Figure~\ref{pic:syscalls} shows a simplified version of the system call implementation on x86 for Linux kernel before 2.5\cite{decade-linux-syscalls}.
More modern versions use the special instructions \texttt{SYSENTER} and \texttt{SYSEXIT} (Intel) or \texttt{SYSCALL} and \texttt{SYSRET} (AMD) instead of the slower trap interrupts\cite{decade-linux-syscalls}.

\begin{figure} [ht]
	\centering
	\includegraphics[scale=0.4]{syscall-lfd}
    \caption{System Call Implementation\label{pic:syscalls}\cite{lfd430}}
    %TODO own picture!
    %TODO add numbers and a kind of flow sequence with numbers. Add numbers to text.
\end{figure}


\subsubsection{POSIX}
The basic idea behind the \acf{posix} standard is to define a stable interface between the user-space and the operating system kernel to archieve portability for applications on systems meeting this standard.
But even if an operating system comply the them, it may differ in the typ and number of available system calls.
\ac{posix} is only an \ac{api} definition but not one for system calls.
An operating system may implement the \ac{posix} standard functions within a library which often involve system calls, but it has not to do so\cite{lfd430},~\cite{glatz2015betriebssysteme}.
System calls are rarely used directly by user applications without an abstraction layer such as libraries. An example is the \textit{libc} on Unix-like systems\cite{lfd430},~\cite{tanenbaum-modern-operating-systems}.
Equally, a system is not constrained to a single \ac{api} and may implement different ones using its existing set of system calls\cite{glatz2015betriebssysteme}.

\ac{posix} is a very common standard which is for example implemented in UNIX, macOS, MACH and partly in Linux\cite{tanenbaum-modern-operating-systems},~\cite{glatz2015betriebssysteme}. 
Another example for an \ac{api} is Win32 used by Windows to abstract their system calls, but as a result, applications targeting the Windows Win32 \ac{api} are not portable to systems implementing the \ac{posix} standard.
% As a result system calls are rarely used directly by user applications without an abstraction layer such as libraries. An example is the \textit{libc}\cite{lfd430},~\cite{tanenbaum-modern-operating-systems}.


\subsection{System Calls in Linux}
In fact, the way system calls are working in Linux was already described as part of the general section. 
The exact mechanism, the calling convention but also the number of system calls is highly depending on the \ac{cpu}'s architecture.
While a 32-bit Linux kernel in version 4.8 for the x86 architecture offered 379 calls, the 64-bit version for x86\_64 offered only 328\cite{lfd430}.
The \textit{man-pages} project documents gives an overview (\texttt{man 2 syscall}) about architectural differences and the calling conventions.
How far Linux is acutally compatible to the \ac{posix} standard is not only related to the kernel and the number of system calls itself, but for the most part to its abstraction layer, the used \ac{posix}/C standard library.
One of the most spread ones, the \textit{glibc} (GNU C Library) aims to follow POSIX.1\-2008 amoungst other standards\footnote{\url{https://www.gnu.org/software/libc/}} while the \textit{musl} library does not implement it in complete\footnote{\url{https://repo.or.cz/w/musl-tools.git/blob_plain/HEAD:/tab_posix.html}}.



\subsection{System Calls in Zircon}
% FIDL, core libs,.. 
% http://research.cs.queensu.ca/~cordy/Papers/BKBHDC_ESE_Linux.pdf
% for vdso
In Zircon, system calls are bounded to the concept of \textit{handles}, a construct which allows applications running in user mode to reference an object in kernel mode\cite{zircon-handle}.
Interactions between user applications and kernel objects are still done using system calls but the most of them are using a handle which describes the kernel object to work on\cite{zircon-concepts}. 
Handles are checked by the kernel each time a system call is triggered.
For additional security, the kernel checks wether
\begin{itemize}
    \item a handle has the correct type for the system call, 
    \item a kernel handles parameters refers to one existing within the calling process's handle table and
    \item a handle has the necessary rights for the triggered action\cite{zircon-concepts}.
\end{itemize}
% 
In contrast to Linux, Zircon provides just one libary for system calls and the standard C implementation, the \textit{libzircon.so}.
It is a \acf{vdso} directly provided by the kernel and not stored as a physical \ac{elf} file on disk.
For the reason that \acp{vdso} are accessable from both, kernel and user mode, without switching the context, they are a perfect concept to implement system calls in a very performant way\cite{vdso-linuxjournal}.
Thus, the Zircon \ac{vdso} is the only way to perform system calls\cite{zircon-vdso}, which is a very elegant solution to cope with performance issues in a microkernel architecture.

The system calls are defined by using a abstract definition syntax and the matching tool \textit{abigen} which generates header files and code for the libzircon and the kernels system call implementation\cite{zircon-concepts}.
Also in contrast to Linux does Zircon respectively Fuchsia not aim for \ac{posix} compatibility.
It implements only a very limited subset of \ac{posix} consisting of basix \ac{io} operations and pthreads.
Zircon does not support Unix-like signals, symbolic links and much more\cite{zircon-libc-posix}.
The libzircon.so does not support directly \ac{io} operations. 
They are performed by the \textit{fdio.so} library which overwrites weak symbols of the libzircon\cite{zircon-libc-posix}.



\section{Processes and Threads}\label{sec:processes-threads}

Modern operating systems are characterized by their ability to perform various tasks at the same time.
So far, this fact has simply been accepted within this work, but it was not questioned what is special about it and how this multitasking is achieved by an operating system.
In general, parallelisation of tasks can take place on different levels, e.g.\ as hardware or software paralellism.
While the physical resources for the first case are actually available to execute the tasks really simultanesouly, it only seems to be so for software parallelism\cite{glatz2015betriebssysteme}.
Hardware parallelism is realized by independent, may specialized execution units such as multiple processing cores or controllers which are able to perform particular parallel to the main \ac{cpu}.
This could be USB, network or graphics controller, for example\cite{glatz2015betriebssysteme}.
In order to create the impression of parallelism on a single \ac{cpu} and to use their available computing power as best as possible, an abstraction to provide pseudo concurrency for the execution of several tasks is required.
According to \textsc{Tanenbaum}, this concept called \textit{process model}, is the most central one of operating systems\cite{tanenbaum-modern-operating-systems}.
The term \textit{process} is often defined as a program in execution\cite{achilles2006betriebssysteme}.
The process model is complemented by the thread model which provides a simplified version for paralellism within a process or an application\cite{glatz2015betriebssysteme}.
The following sections take a closer look at these concepts and answer the remaining questions, in particular about the process and thread model, synchronization mechanisms, inter process communication and their implementation in Linux and Zircon.


\subsection{Processes}
% model, what is a process
% \cite{glatz2015betriebssysteme}:
% each process has virtually the whole cpu and corresponding resources for itself (cpu, register, address space)
% process model realizes/coordinates the parallel execution of more than one process -> time multiplexing
% reality: num processes > num cpu cores -> pseudo parallel execution
%
% \cite{tanenbaum-modern-operating-systems}: process model
% runnable software is organized as a number of sequential processes, process is an instance of an executing program including its current values (pc, registers, variables) -> each one has its own virtual cpu -> real cpu switches different processes -> called multiprogramming
%
% programm needs to be in a defined format (object file format)
% \cite{silberschatz} program is a passive entity -> executable file, process is an active entity (pc, ...)
%
% -> vordergrund/hintergrundprozesse (ui, deamon processes)
% foreground(background) background -> not associated with users but with specific function -> deamon (accept incomming mail, ..) \cite{tanenbaum-modern-operating-systems}

% process implementation

% process is different in different systems -> needs something like a processor control block (pcb) (containing all relevant data, an id (pid), process state, process context,...)
% -> for a parallel execution we need to switch between them -> context switches
% process needs to be paused and resumed -> relevant information needs to be stored and restored -> cpu register contents (pc, sp, psw), process relevant memory contents (stack), register contents are copied to pcb and restored from there, memory content stays -> each process gets a private part of the memory
%
% \cite{achilles2006betriebssysteme}  process contains memory segments -> programm code, data segement(s), stack, heap + exclusive resouces and if cpu is active -> cpu register -> saved in pcb if process is interrupted (contains id, priority, process rights, maximum resources (max cpu time, max files open, ..), actual resources (actual cpu time, ...)
%
% \cite{tanenbaum-modern-operating-systems}
% process table -> one entry per process (process control block) -> contains information about the process's state (pc, stack pointer, memory allocation, status of open files, accounting and scheduling information, priority, pid, parent process, ...)
%
% \cite{silberschatz}
% pcb: process state (running, waiting,...), program counter, cpu registers, cpu scheduling information, memory management information, accounting information (maximum and actual cpu time used, time limits, account numbers, ..), io status information (io devices, open files, ... allocated by this process)
%
% process states
% \cite{tanenbaum-modern-operating-systems} process states
% running actually using cpu
% ready runnable, temporary stopped to run other process
% blocked unable to run until sth external happens, e.g. a resource is freed
%
% \cite{silberschatz}
% new -> process is being created
% running ->
% waiting -> (blocked)
% ready
% terminated
%
% % lifecycle
% \cite{mandl2014Grungkurs}
% pic mandl
% pic silberschatz
% 1 os activates process
% 2 os interrupts other process/ preemption
% 3 process is blocked (waits for input, resources)
% 4 reason for blocking is not longer available -> resources are available
% 5 process is terminated (in(voluntary))
% -> pic tanenbaum

% multiprogramming model

% programm needs to be in a defined format (object file format)
%
% \cite{tanenbaum-modern-operating-systems}
% improves cpu utilization
% - hardware stacks pc, ...
% - hardware loads new pc from interrupt vector
% - registers are saved
% - new stack is setuped
% - interrupt service runs (reads and buffers input)
% - scheduler decides which process is to run next
% - new process is started
% process start
% \cite{glatz2015betriebssysteme}, \cite{tanenbaum-modern-operating-systems}
% process start:
% -system start (initialisation)
% -system service call for process creation (through a running process)
% -application start (via user)
% - init batch job
%
% -> vordergrund/hintergrundprozesse (ui, deamon processes)
% foreground(background) background -> not associated with users but with specific function -> deamon (accept incomming mail, ..) \cite{tanenbaum-modern-operating-systems}
% types of new processes
% process chaining -> unix exec
% process forking -> unix fork
% process creation -> (threads pthread create, win thread create), win process create
% % data for new processes
% data for new process -> inherit of all data (need to share same programm code), data buffer which is init via old process (via ipc), new process with initial values e.g. via sys call params
%
% inherit -> fork, win createprocess (\cite{achilles2006betriebssysteme}: both processes running at the same time, or parent waits for child to be ended, both share all resources/ a part of them /none, address space: child is a duplicate of parent/ child runs a new programming)
% ipc -> unix popen
% initial params -> posix pthread create, win create thread
% % process termination
% \cite{glatz2015betriebssysteme}, \cite{tanenbaum-modern-operating-systems}
% termination:
% - normal exit (voluntary)
% - ahead of time , error exit (self detected error, voluntary)
% - ahead of time (fatal error, detected by system) (not voluntary)
% - terminated/killed by other process (not voluntary involuntary)


The term \textit{process} describes an instance of a program in execution, including all its required resources to enable a model for the pseudoparallel execution of multiple programs based thereon\cite{silberschatz2009operating},~\cite{tanenbaum-modern-operating-systems}.
Each program in execution is modeled as a seperate process which is assigned to a virtual private \ac{cpu} including \ac{cpu} registers, above all the program counter (PC) and a virtual private address space\cite{tanenbaum-modern-operating-systems}.~\cite{glatz2015betriebssysteme}.
Especially by using virtual private memory, processes are not only modeled individually, but are also isolated from each other in reality in order to prevent errors or deliberate attacks between programs\cite{brause2017betriebssysteme}.
But since in reality more processes, respectively programs, have to be executed than \acp{cpu} exists, a mechanism is needed to switch between processes and allow the execution of all them.
This mechanism behind, the \textit{multiprogramming model}, and the policies called \textit{process scheduling} will be considered hereafter.

However, for a change between the execution of programs to succeed, a process must contain information about its state at the moment it is interrupted to run another one.
Which information need to be stored and the way it is done is slightly depending on an effective system's design and its implementation.
In general, these information are stored in a structure called \textit{process control block} in literature\cite{tanenbaum-modern-operating-systems}.
Depending on the implementation, it contains for example
\begin{itemize}
    \item an process id, 
    \item the process's state,
    \item the \ac{cpu}'s register contents, especially the program counter (PC), the stack pointer (SP) and the processor status word (PSW),
    \item the process's address space including the program code, its stack and heap and data segments, 
    \item information about resources allocated by the process like open files, or \ac{io} devices,
    \item \ac{cpu} scheduling and accounting information like a priority, the maximum and actual computing time for this process,
    \item the parent process and
    \item the process's rights\cite{tanenbaum-modern-operating-systems},~\cite{glatz2015betriebssysteme},~\cite{achilles2006betriebssysteme},~\cite{silberschatz2009operating}.
\end{itemize}

\subsubsection*{Process Lifecycle}
The state in the list above refers to a process's lifecycle.
It is quite easy and in most cases described as a state chart like pictured in figure~\ref{pic:process-lifecycle}.
Once a process was created, it is managed by the operating system and changes its state to \textit{ready}.
The process is ready to run, but has to wait until the system allocates a \ac{cpu} to it.
Is that the case, the process changes its state to \textit{running} and performs its calculations.
If a process is interrupted (preempted) by the operating system without having fulfilled its task completely, there can be two reasons for this which result in different subsequent states.
Was the process interrupted just to run another one, the process's state changes back to \textit{ready}. 
It only lacks on \ac{cpu} time to run the process again.
If the reason was instead that resources like the process is waiting for an external event or required \ac{io} devices are used by another process, so it changes its state to \textit{waiting} or \textit{blocked}. 
Only when the blocking resource needed by the process is available again, the operating system changes the status of the process to \textit{ready} again.
The process is prepared to get reassigned to a \ac{cpu}.
A running process finishing its task during its computing time has reached the end of its life, its state changes to \textit{terminated}.
The operating system destroys the process and frees related resources\cite{silberschatz2009operating},~\cite{mandl2014Grundkurs}.

\begin{figure} [ht]
	\centering
	\includegraphics[scale=0.4]{process-states-silberschatz}
    \caption{Lifecycle of a process\label{pic:process-lifecycle}\cite{silberschatz2009operating}}
    %TODO own picture!
\end{figure}

The model described applies to each individual process.
For the coordination of the entirety of processes, the schedule, an operating system kernel's component is responsible.
It is a good example for the seperation of mechanism and policy.
The mechanism behind is based on the \textit{multiprogramming} model as the switching of the \ac{cpu} between programs is called.
It not only allows the impression of parallelism on a single processing core, but also increases its utilization, as many processes spend a lot time waiting for external events such as keyboard inputs\cite{tanenbaum-modern-operating-systems}.

Principally, the mechanism behind scheduling does not differ fundamentally from the treatment of an ordinary interrupt.
First, the programm counter (PC) is saved prior to the new PC is loaded from the interrupt vector and the \ac{cpu}'s registers are saved.
After a new stack was setup, the actual interrupt service runs before the scheduling policy decides which process is to run next and the selected one is started\cite{tanenbaum-modern-operating-systems}.

\subsubsection*{Process Creation}
There are several reasons why a new process should be started and scheduled at all.
The most basic one is the systems start-up.
To initialise an operating system are numerous processes created to execute parts of the system itself.
The user perceives very few of them directly, since the most of them are \textit{background processes} performing specific tasks like accepting incoming mails.
Often, long running processes without user interaction are refered as \textit{deamon processes}\cite{glatz2015betriebssysteme},~\cite{tanenbaum-modern-operating-systems}.
They are mostly generated from the \textit{init process}, the first one running and bringing up the system.
Foreground processes, the ones an user interacts with, are more often started on behalf of the user.
Besides, a process can also be started by a system service call from an existing process.
The last option, that a process is started to execute a batch job is rare today apart from scientifc high performance computers\cite{tanenbaum-modern-operating-systems},~\cite{glatz2015betriebssysteme}.
%TODO graphic

Also for the way how a new process can be started there are several options.
Using \textit{process chaining}, a running process starts an independent new one, a new \ac{pcb}, and destroys itself\cite{achilles2006betriebssysteme}.
An example is the Unix implementation of \texttt{exec()}\cite{glatz2015betriebssysteme},~\cite{tanenbaum-modern-operating-systems}.
By \textit{forking a process}, a second one that is, at least in the beginning, a copy of the original one.
Both remains exiting and share the same environment such as program code, address space and resources\cite{tanenbaum-modern-operating-systems}.
As a result, both processes have access to the exactly same resources like opened files or \ac{io} devices\cite{achilles2006betriebssysteme}.
The Unix implementation of \texttt{fork()} is an example for this way of process creation.
Process \textit{forking} and \textit{chaining} are usually used combined in Unix-like systems to create a new, independent process which is running in parallel to the first one\cite{tanenbaum-modern-operating-systems}.
In contrast, Windows offers a third way the \textit{process creation} which combines them in a single instruction to start a second, independent process (\texttt{CreateProcess()})\cite{glatz2015betriebssysteme}.

Are the newly created process and its parent share the same program code, the new one can simply inherit all needed data from its parent like it is done by \textit{process forking}\cite{achilles2006betriebssysteme}.
Since each process has its own virtual address space if not shared through inheritance, so the data cannot be copied there without further ado.
This is not only necessary for the multiprogramming model, but also a security mechanism that encapsulates and protects applications in execution against each other, called \textit{process isolation}.
Is is the case, e.g.\ for the once created via \textit{process creation}, an operating system needs a mechanism to pass data to the created process.
As a solution, a mechanism for the communication between processes with which the parent process communicated the new data to the child one via a buffer is just as conceivable as the use of inital parameters which are transmitted during the process creation, e.g.\ via a system call\cite{glatz2015betriebssysteme}.
The first option is used by the \texttt{popen()} call of Unix-like systems while the mechanism behind the \textit{\ac{ipc}} takes a major role in modern operating systems and therefore is treated in a seperate section.
The second one is more often used for \textit{threads} which are the topic of the following section.

\subsubsection*{Process Termination}
Reaching the end of its lifecycle (see figure~\ref{pic:process-lifecycle}), a process terminates itself regulary and voluntary (\textit{normal exit})\cite{tanenbaum-modern-operating-systems}.
In addition, a process can terminate itself prematurely for various scenarious or be terminated by the operating system or other processes.
For example, a process may detect an internal error and voluntary terminates itself ahead of time or the operating system detects such an error and terminates the process involuntary to avoid major damage\cite{tanenbaum-modern-operating-systems}.
Besides, a process may gets involuntary terminated or killed by another process. 
Killing another process is in common a privileged task which require an authorization or extended rights\cite{tanenbaum-modern-operating-systems}.


\subsection{Threads}

% whats a thread why threads

% \cite{mandl2014Grundkurs}: processes are expensive, threads are resource-saving -> a concurrent execution unit within a process, also named light-weight process (LWP), all threads within a process share the same addres space, the one of the process -> same process data, program code, global variables, resources -> light-weight because they share the resources
% besides the inherit context of the process (containing open files, ...) they have an own stack for local vars, own register and pc
%
% \cite{brause2017betriebssysteme}: processes needs much memory (not the address space alone but also the pcb entry) -> for a number of processes it is more than can be cached in ram -> switching processes is a heavy operating and takes a long time
% much applications do not need a completely new contest, but threads for execution within one process -> app waits for keyboard input and checks text for errors at the same time
% -> threads as solution (lwp)
%
% \cite{glatz2015betriebssysteme}: basic idea: parallel actions based on the same resources (address space, files, io devices) -> parallel actions within a process, process manages the resources and threads -> no isolation or saftely between threads -> data may get corrupted/seen by another thread in the same process
% process manages resources, thread executes the code -> each process contains at least one thread to execute code
%
%
% processes are used to group resources together, threads are the entities scheduled for the execution on the cpu
% threads: allow multiple executions to take place in the same environment. (multithreading)
%
% \cite{silberschatz2009operating}: benefits: responsiveness, resource sharing, economy (allocation memory and resources for process creation is costly), scalability (multiprocessor arch)

The current process concept, as previously introduced, provides only a single thread of execution.
However, this an issue as soon as a resource needs to be edited in parallel.
If an user edits a file for example, the process has to wait for the user's input repeatedly. 
It is nearly impossible to check this input for errors at the same time, since a second process is not allowed to access resources allocated by another process without an explicit action of programmers (like explicit \acl{ipc})\cite{tanenbaum-modern-operating-systems},~\cite{brause2017betriebssysteme}.

The \textit{thread model} should solve this issue.
Its basic idea is to equip a process with several execution threads that work on the same resources running in quasi-parallel\cite{tanenbaum-modern-operating-systems}.
This means processes only group the resources together while \textit{threads} represent the actual execution units on the \ac{cpu}\cite{tanenbaum-modern-operating-systems}.
A program is still abstracted as a process while (parallel) sequences within the program correspond to threads.
As a result, \textit{threads} can be considered as slimmed down processes sharing the same address space and physical resources.
Each thread has its own \acp{pc}, register set, stack and state, but the address space, global variables, open files and accounting information are shared\cite{tanenbaum-modern-operating-systems}.
A thread's lifecycle is equivalent to process's ones, but in contrast to them are threads not isolated and protected against each other\cite{glatz2015betriebssysteme}.
As they share the same address space, one thread can read, write or even destroy another thread's private stack\cite{tanenbaum-modern-operating-systems}.
Another issue are competing threads that try to write the same global data.
They cause a \textit{race condition} which possibly result in inconsistent or wrong data\cite{brause2017betriebssysteme}.

Nevertheless, the advantages of using \textit{threads} (multithreaded programming) predominate.
The most important one is resource sharing. 
The fact multiple threads using the same resources by default, e.g.\ files, in pseudoparallel are the biggest advantage but at the same time the biggest problem of this concept.
Threads enable responsive, interactive applications and increase the performance especially on multiprocessor architectures they can run truely parallel\cite{silberschatz2009operating}.
Another reason is an economic one.
While allocating an address space and physical resources to create a process is an expensive operation, creating a thread is not as they inherit exactly these components from their corresponding process\cite{silberschatz2009operating},~\cite{mandl2014Grundkurs}.
Threads only need to setup their own \ac{pc}, registers, stack and a state within a process. 
That's why they are also known as \acf{lwp}\cite{mandl2014Grundkurs}.

How \textit{light-weight} they actually are depends a lot to their implementation in an operating system.
Conceivable options are thread implementions in userspace or kernel space, but also hybrid ones. 
Implementing them as user library requires an own mechanism to schedule threads within a process which is often realized as a kind of runtime environment including a \ac{tcb} (according to \ac{pcb}) for each single process\cite{mandl2014Grundkurs},~\cite{tanenbaum-modern-operating-systems}.
There is no need to invoke the operating system to switch a thread, but as a result all threads within a process block become blocked if a single one waits for a resource\cite{tanenbaum-modern-operating-systems},~\cite{brause2017betriebssysteme}. 
The operating system's schedule just do not know about the runtime environment and possible other runnable threads within a process.
The implementation in kernel space is not that light-weight, but multicore architectures benefits more from this variant.
If the operating system's kernel has the control over threads, these are managed just like processes.
Instead of one \ac{tcb} within each process, the kernel collects the \acp{tcb} for all threads in the entire system in a thread table according to the process table\cite{tanenbaum-modern-operating-systems},~\cite{mandl2014Grundkurs}.
But this also allows the kernel to recognize a blocked thread and schedule another one of the same process instead of blocking the whole process\cite{tanenbaum-modern-operating-systems}.


% % how are threads implemented
% \cite{mandl2014Grundkurs} threads may be implemented in both, kernel(os coordinates scheduling, better multiprocessor support, not blocking if a single thread blocks, but needs context switches, system dependent) and userspace(in this case, an userlib schedules threads within a process, no context switch to kernel needed, but all threads are blocked if a single one waits for resources), own data structure -> thread control block tcb, all tcb are collected in a thread table, have an own state, pc, registers and stack but now an own address space -> no seperate unit -> always exist in process context
%
% no context switch needed as threads share the same memory region/address space -> reduces system overhead, threads support parallelism -> good for mulitcore cpus, fine grained mechanism for parallelism
%
% \cite{brause2017betriebssysteme} mostly implemented as user library -> fast thread switches -> no os needed, a waiting thread blocks the whole process
% os impl: better for mulitcore ps, with real parallel threads, just blocking one thread but not the whole process
%
% \cite{tanenbaum-modern-operating-systems} userspace threads, kernel space threads , hybrids
% userspace: each process needs its own private thread table to keep track (analog to process table)
% kernel: no runtime system needed, no thread table in each process -> kernel has a thread table that keeps track of all threads in system (table holds registers, state and other information, subset of information tracked about processes), one blocking thread does not block the whole process, (e.g. one thread causes a page fault, other thread can be runned until the page is loaded) (more expensive than user threads)
% hybrids:


\subsection{Synchronization}
% (synchronization)
% wait for other process:
% join -> follows to forking waiting is compulsory
%
% join -> unix process (wait, waitpid), posix thread (pthread join)
% wait -> windows process/thread  wait for single object


% race conditions
    % \cite{tanenbaum-modern-operating-systems} : threads share storage that one can read and write (e.g. main memory) -> thread a reads a value, thread b reads a value. thread b writes a new value, thread a will also write a new value but startig from the value read before. -> inconsistent
    % -> race condition : two or more processes (via ipc) or threads try to read and write shared data -> the final result depends on who runs in which order
    % \cite{glatz2015betriebssysteme} lost update problem -> race conditions, inconsistent read
%
    % \cite{silberschatz2009operating} for operating systems: just an issue on preemptive kernels (allows a process to be preempted while it is running in kernel mode), a nonpreemptive kernel does not allow a process running in kernel mode to be preempted -> kernel mode process will run until it exits kernel mode, blocks or voluntary yields control of the cpu -> a nonpreemptive kernel is essentially free grom race conditions on kernel data structures as only one process is active in the kernel at a time -> preemptive kernel is more suitable for realtime tasks -> more responsive
%
% critical regions
    % \cite{tanenbaum-modern-operating-systems}: avoid race conditions -> allow only one process to read/write shared data at the same time -> mutual exclusion -> if one process/thread use a shared date, all other processes are excluded from doing the same -> race conditions are only caused by access shared memory, files or resources -> critial section/region, other actions do not harm
    % mutal exclusion can be achieved via busy waiting
        % - disabling interrupts (single processor system, disable all interrupts after entering a critical region, reenable just before leavin) -> no clock interrupt, process no process intervene, but a userprocess is able to disable interrupts -> dangerous, may stopps everything but the running process (never re-enable interrupts) -> not suitable for multicore processors, ok for os itself
        % - lock variables: same issue as race conditions itself
        % - peterson's solution/ dekker -> software realization not further interesting \cite{glatz2015betriebssysteme} bakery algorithm (lamport) \cite{silberschatz2009operating}
%
%
        % - hardware support via tsl instruction (test and set lock) -> cpu locks the memory bus to prohibit other cpus from accessing memory until done -> cpu still runs, scheduler still work, just memory bus is locked (used in enter region, removed in leave region) (alternative instruction: XCHG -> exchanges the contents of two locations atomically -> used at intel cpus) -> one atomar operation
        % \cite{silberschatz2009operating}
%
        % \cite{glatz2015betriebssysteme} tsl is sometimes called TAS (test and set) -> makes platform dependet code
%
        % peterson and tsl/xchg do busy waiting
            % -> spinlock: lock that is busy waiting (for a reasonable expectation the wait will be short, if not avoid -> wastes CPU time)
            % -> waist cpu time
%
    % \cite{achilles2006betriebssysteme}
    % - combine operations to one uninterruptable atomar operation -> intel test and set instruction
    % - lock interrupts -> they will be collected and done later (after the interrupts are unlocked again) -> just for short sections, just for single core
%

Already the previous section mentioned that the ability of threads to access shared data not only has advantages.
As they share storage, e.g.\ main memory, two threads can read and write the same value.
But what happens if both of them try to access the same, shared value?
Two threads try to read and modify a shared value are given.
Both read the value and calculate based on the read a new one to store. 
There is no problem as long as they just read the same value, but it occures on updating the value.
May the first thread is scheduled first and updates the value, directly following the second one is scheduled and updates the value based on the value read before the first thread was executed.
In this case, the update of the first thread is lost. 
The data becomes inconsitent.
Such a situation is called \textit{lost update problem}\cite{glatz2015betriebssysteme}.
Unless the scheduling of the threads is predictable in each situation, it remains impossible to predict the exact outcome of it.
Therefore, one speaks of a \textit{race condition}\cite{tanenbaum-modern-operating-systems}.

Race conditions are each time a topic where several processes or threads work on the same data in any way.
This also applies to an operating system's kernel.
Except for non-preemtive kernels which can guarantee that only one thread is active at a time\cite{silberschatz2009operating}.
In contrast to preemptive kernels, non-preemptive ones do not allow a thread running in kernel mode to be interrupted. 
The thread runs until it exits kernel mode, blocks or yields the control of the \ac{cpu} voluntary\cite{silberschatz2009operating}.
Only in such a case can be guaranteed that a kernel and its data structures are free of race conditions.
However, preemptive kernels are more common because they are more responsive and better suited for real-time tasks due to their interruptibility\cite{silberschatz2009operating}.
Furthermore, with today's multicore systems is it rather unlikely to fulfil the requirement of only one active thread in kernel space.

For this reason, a mechanism to prevent race conditions on both, user and kernelspace, is needed.
The basic idea to achieved this is to exclude chance that a thread that wants to change a shared resource cannot be interrupted by another one that wants to work on the same resource\cite{tanenbaum-modern-operating-systems}.
But only certain areas in the program code are critical. 
The ones a shared resource is processed.
They are called \textit{critical regions} or \texit{critical section}\cite{tanenbaum-modern-operating-systems}.
Other regions do not harm if they are interrupted.
If only one thread at a time is allowed in critical sections and another one is only allowed to enter the region as soon as the competing access is completed, this is called \textit{mutual exclusion}\cite{tanenbaum-modern-operating-systems}, \cite{glatz2015betriebssysteme}.

The easiest way to achieve \textit{mutual exclusion} is to completely disable the system's interrupts immediately after entering a critical region and reenable them just before leaving the region.
In the meantime, all incoming interrupts are collected and processed as soon as they become reenabled\cite{achilles2006betriebssysteme}.
However, this method is not suitable for modern multicore systems since the interrupts can only be locked for the current \ac{cpu} core.
The competing thread can still modify the resource if executed on a different core.
This solution is not ideal for single core systems, too, because even the clock interrupt is disabled and with this the process scheduling.
Does the currently running not reenable the interrupts, the whole system is blocked\cite{tanenbaum-modern-operating-systems}.

While there are some approaches to pure software solutions such as the algorithms of \textsc{Peterson} or \textsc{Dekker} (see \cite{tanenbaum-modern-operating-systems} or \cite{silberschatz2009operating} for further information) are hardware enabled solutions common today\cite{tanenbaum-modern-operating-systems}.
Modern multicore \acp{cpu} usually offer an instruction which is referred as \ac{tsl} or \ac{tas} in literature.
It is an atomar, not interruptible operation, usually used to modify a shared variable which controlls the access to a shared memory region\cite{tanenbaum-modern-operating-systems}.
This is in common achieved by locking the memory bus to prevent other \acp{cpu} from accessing the memory until the operation is done.
As a big advantage of this solution, the \ac{cpu} cores are not obstructed.
Common calculations are not impeded but memory accesses are prevented\cite{tanenbaum-modern-operating-systems}.
A variant is the \ac{xchg} instruction which exchanges the content of two memory locations in one atomic operation\cite{silberschatz2009operating}.

All mechanisms mentioned so far have one problem: they require busy waiting.
The thread waiting is still active and waists \ac{cpu} time.
For short waits, this is perfectly fine.  
Switching to another thread and back would be more expensive in such a situation\cite{glatz2015betriebssysteme}. 
Thus there are locking mechanisms that implement busy waiting very efficiently, called \textit{spinlocks}\cite{tanenbaum-modern-operating-systems}.
But longer active waits are very inefficient.
In this case, it is better to use blocking waits and bring another thread in execution until the reason for the blocking is removed, e.g.\ the desired resource is freed again.

\subsubsection*{Semaphores and Mutexes}
\textsc{Dijkstra} suggested in 1965 a possibly blocking lock mechanism called \textit{semaphores} based on a \ac{cpu}'s \ac{tsl} instuction and easier to use for application developers.
A \textit{semaphore} is a new integer typ with two related operations called \textit{P} and \textit{V} in the original paper or \textit{down} and \textit{up} in some literature and implementations\cite{glatz2015betriebssysteme}.
% The semaphore is initally initialized with a value greater 0, the exact one depends on a system's implementation or can be defined by a programmer.
If the \textit{P} or \textit{down} operation is executed on a semaphore, it is checked whether the value is greater than 0, decrements the counter if it is the case and continues. 
If not, the thread is put to sleep.
The operation remains unfinished until a \textit{V} or \textit{up} operation was executed and incremented the semaphores value.
One of the possibly multiple threads sleeping on a semaphore is randomly or by a certain rule choosen by the operating system and gets the clearance to complete the \textit{P} or \textit{down} operation\cite{tanenbaum-modern-operating-systems}.
For a semaphore, the fact updates on its value must be performed in an atomic operation is essential\cite{silberschatz2009operating}.
Neighter the decrementing of the value performed in the \textit{P} operation nor the incrementing in \textit{V} may be interrupted.

If semaphores are actually blocking depends on the implementation.
As mentioned earlier is a blocking mechanism not always advantageous, e.g.\ for very short waits or multicore systems with real parallelism.
In this cases, its is potentially more efficient to use busy waiting with spinlocks\cite{glatz2015betriebssysteme}.

%TODO variant mutexes
\ \\
\ \\

        % blocking /rescheduling solutions
% mutexes semaphores
            -> semaphores : integer variable with two operations: down and up -> down checks if the value is greater than 0 (initial value depends), if so it decrements the value and continues, if 0 the process is put to sleep without completing  the down for the moment -> checking the value, changing it and possiby go to sleep is a a indivisible atomic action on a semaphore (guaranteed) 
                up operation : increments the value of the semaphore -> if one or more processes were sleeping on that semaphore, one of them is (randomly) choosen by the system and allowed to complete down -> no process ever blocks doing an up 
                original paper down = P, up = V \cite{glatz2015betriebssysteme}
                \cite{glatz2015betriebssysteme} P and V are not divideable -> atomic operations
                if the waiting time is very short or a we have a multicore system with real paralellism, blocking becomes very unattractive (needs two process changes) -> active waiting with spinlocks

                -> binary semaphores -> mutex (initialized to 1) -> guarantees mutal exclusion by using them for critical regions,  two states (locked/unlocked) (can be implemented with tsl/xchg) -> schedule another thread instead busy waiting, try again in next schedule cycle (as long as mutex is locked)

 
                -> spinlock: lock that is busy waiting (for a reasonable expectation the wait will be short, if not avoid -> wastes CPU time)
            -> waist cpu time

        
                -> futex: fast userspace mutex, spinlocks are fast if waiting is short, waste cpu time if not -> blocking - and let the kernel unblock but switching to kernel is expensive -> futex as solution -> avoids dropping into the kernel unless it really has to -> consists of two parts : kernel service provides a wait queue that allows multiple processes to wait on a lock, kernel explicitly unblocks them, put a process on the wait queue requires an expensive syscall -> should be avoided -> user lib is completely in userspace (atomic function (decrement and test/ increment and test)) -> needs a syscall but does not spin  -> kernel is only invoked if there is a contention  

% monitors
programming language construct to simplify ipc communication -> refer to tanenbaum-modern-operating-systems or \cite{mandl2014Grundkurs}
\cite{silberschatz2009operating} monitors e.g. implemented with semaphores

 % barriers
\cite{glatz2015betriebssysteme} two or more threads needs to be synchronized in a way they wait for each other in their program flow. -> barriers -> both threads must reach a synchronization point (barrier) before both are allowed to continue -> one thread needs to wait for the other one -> can be realized with semaphores


% priority inversion
            -> priorit inversion (two processes, H & L, (H runs whenever becomes ready) low runs, get in a critical section. H becomes ready and is scheduled -> but L is in a crit section and can never leave, while H is busy waiting
            \cite{glatz2015betriebssysteme}: pathfinder (marssonde) -> solution: priority inheritance -> means that when a thread waits on a mutex ownd by a lower priority thread, the priority of the owner is increased to that of the waiter. -> operating system mechanism

% synchronisation issues
                \cite{mandl2014Grundkurs} other synchronization problems: blocking (a process is blocked because a second one holds a needed resource, until the second one frees the resource), starvation (process is ready but does not get cpu time because higher prior processes are preferred) , deadlock (process 1 holds resource A and needs resource b, process 2 holds resource b and needs resource a -> non of them frees its resource -> cyclic dependencies -> both are blocked forever)


                \cite{silberschatz2009operating} \cite{glatz2015betriebssysteme} further synchronization problems: producer-consumer, readers and writers, dining philosophers (tanenbaum-modern-operating-systems, \cite{mandl2014Grundkurs})



\subsection{Inter Process Communication}

% message based communication

    (synchron / asynchron) \cite{glatz2015betriebssysteme}: 
    synchron: receiver has to be ready to receive data (one have to wait for the other to become ready)
    asynchron: sender sends even if receiver is not available to receive (needs a buffer to store data temporarily, decoupled, helps to compensate speed diverences in data processing, sender only resumes to send if the previous data is fully stored in the buffer) buffer is called mailbox or message queue, message size depends on impl -> messages need an identification (name, descriptor, handle)

    \cite{glatz2015betriebssysteme}: communication via system functions
    via messages (message passing), data streams (streaming), packets (packeting)
    message: delimited amount of data
    stream: theoretical unlimited, for sender/receiver not visible
    packet: standardized formats (communication protocols), not visible for applications, fragmentated transfer, deframentation at receiver -> hidden by networking impl

    \cite{tanenbaum-modern-operating-systems} 
    message passing: two primitives: send/receive (rather system calls than language constructs), if no message available, receiver can block until one arrives (or return immediately with an error code)
    issue: lost messages -> receiver send back an acknowledgement message, if sender does not receive it within a certain time, it retransmits the message -> message was received, but ack is lost -> message got retransmitted -> receiver get it twice -> need to distinct between both, e.g. via sequence numbers (same number for a resent message) 
    example: MPI (message passing interface)

% memory based communication

% socket

% rpc


\subsection{Processes and Threads in Linux} 
\cite{silberschatz2009operating}

\subsection{Processes and Threads in Zircon}


\section{Scheduling}\label{sec:scheduling}

\subsection{Scheduling in Linux}
\subsection{Scheduling in Zircon}


\section{Memory Management} %TODO label
%    Linux Concept -> LFD430 pic
%TODO find sections
%TODO how is it done in Linux and Zircon
\subsection{Address Spaces}
\subsection{Virtual Memory}
\subsection{Page Replacement/Paging}
\subsection{Memory Management in Linux}
\subsection{Memory Management in Zircon}


\section{I/O} %TODO label
%TODO review sections, how is it done in Linux/Zircon
\subsection{I/O Hardware}
\subsection{Memory Mapped IO}
\subsection{Direct Memory Access}
\subsection{Interrupts}
\subsection{Power Management}

   
\section{Security Concepts} %TODO label
\subsection{Access Control} %Domains, Capabilities
%DAC, MAC, ..
\subsection{Security Concepts in Linux}
\subsection{Security Concepts in Zircon}


\section{Driver Models} %TODO label
